{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safelog(vals):\n",
    "    return np.log(np.maximum(vals, 1e-10))\n",
    "    \n",
    "def normalize(vals):\n",
    "    return vals / np.sum(vals, axis=1, keepdims=True)\n",
    "\n",
    "def generate_lexicons(n_words, n_meanings):\n",
    "        arrays =  np.array([list(map(int, list(np.binary_repr(i, width=n_words*n_meanings)))) \n",
    "                            for i in range(2**(n_words*n_meanings))])\n",
    "        lexicons = arrays.reshape((2**(n_words*n_meanings), n_words, n_meanings))\n",
    "        return lexicons[lexicons.sum(axis=1).min(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRSA:\n",
    "    def __init__(self, alpha, prior, C, contexts):\n",
    "        self.contexts = contexts\n",
    "        self.alpha = alpha\n",
    "        self.prior = prior\n",
    "        self.C = C\n",
    "\n",
    "    @staticmethod\n",
    "    def safelog(vals):\n",
    "        with np.errstate(divide='ignore'):\n",
    "            return np.log(vals)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(vals):\n",
    "        return np.nan_to_num(vals / np.sum(vals, axis=-1, keepdims=True))\n",
    "    \n",
    "    def L_0(self, L, c):\n",
    "        return self.normalize(L * self.prior * self.contexts[c])\n",
    "    \n",
    "    def S_p(self, L, c):\n",
    "        return self.normalize(np.exp(self.alpha * (self.safelog(self.L_0(L, c).transpose(0, 2, 1)) - self.C)))\n",
    "    \n",
    "    def L_p(self, L, c):\n",
    "        return self.normalize(self.S_p(L, c).transpose(0, 2, 1) * self.prior * self.contexts[c])\n",
    "\n",
    "class Agent(BaseRSA):\n",
    "    def __init__(self, alpha, prior, C, n_words, n_meanings, contexts):\n",
    "        super().__init__(alpha, prior, C, contexts)\n",
    "        self.Lexicons = generate_lexicons(n_words, n_meanings)\n",
    "        self.prob_lexicon = np.ones(len(self.Lexicons)) / len(self.Lexicons)\n",
    "        self.n_words = n_words\n",
    "        self.n_meanings = n_meanings\n",
    "    \n",
    "    def speaker(self, m, c):\n",
    "        # index of the lexicon with the highest probability given prob_lexicon\n",
    "        lexicon_idx = np.random.choice(np.arange(len(self.Lexicons)), p=self.prob_lexicon)\n",
    "        return self.S_p(self.Lexicons, c)[lexicon_idx][m].argmax()\n",
    "    \n",
    "    def listener(self, w, c):\n",
    "        # index of the lexicon with the highest probability given prob_lexicon\n",
    "        lexicon_idx = np.random.choice(np.arange(len(self.Lexicons)), p=self.prob_lexicon)\n",
    "        return self.L_p(self.Lexicons, c)[lexicon_idx][w].argmax()\n",
    "    \n",
    "    def update(self, w, m, c):\n",
    "        self.prob_lexicon = self.normalize(self.L_p(self.Lexicons, c)[:, w, m] * self.prob_lexicon)\n",
    "        # update prob_lexicon using L_0\n",
    "        # self.prob_lexicon = self.normalize(self.L_0(self.Lexicons, c)[:, w, m] * self.prob_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.array([0.1, 0.45, 0.45])\n",
    "alpha = 0.1\n",
    "C = np.array([0, 20])\n",
    "contexts = np.array([[1, 1, 0], [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_round(a, b, m, c):\n",
    "    w = a.speaker(m, c)\n",
    "    g = b.listener(w, c)\n",
    "    if m == g:\n",
    "        a.update(w, m, c)\n",
    "        b.update(w, m, c)\n",
    "    return m == g, w, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1c/pphtjl397rnbdcp94xmwzkqr0000gn/T/ipykernel_37194/1869911606.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nan_to_num(vals / np.sum(vals, axis=-1, keepdims=True))\n"
     ]
    }
   ],
   "source": [
    "posteriors = []\n",
    "logs = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for t in range(100):\n",
    "    a = Agent(alpha, prior, C, 2, 3, contexts)\n",
    "    b = Agent(alpha, prior, C, 2, 3, contexts)\n",
    "\n",
    "    for _ in range(100):\n",
    "        m = np.random.choice([0, 2])\n",
    "        logs[t][_]['meaning'] = m\n",
    "        # if meaning is 0, context is either 0 or 1, if 1, context is 0, if 2 context is 1\n",
    "        c = np.random.choice([0, 1]) if m == 0 else m - 1\n",
    "        logs[t][_]['context'] = c\n",
    "        if _ % 2 == 0:\n",
    "            tr, w, g = one_round(a, b, m, c)\n",
    "            logs[t][_]['word'] = w\n",
    "            logs[t][_]['guess'] = g\n",
    "            logs[t][_]['correct'] = 'True' if tr else 'False'\n",
    "        else:\n",
    "            tr, w, g = one_round(b, a, m, c)\n",
    "            logs[t][_]['word'] = w\n",
    "            logs[t][_]['guess'] = g\n",
    "            logs[t][_]['correct'] = 'True' if tr else 'False'\n",
    "\n",
    "    posteriors.append(a.prob_lexicon)\n",
    "    posteriors.append(b.prob_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors = np.sum(posteriors, axis=0)\n",
    "posteriors = posteriors / np.sum(posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the posterior distribution of the lexicons\n",
    "plt.bar(np.arange(len(posteriors)), posteriors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# get the lexicon with the highest probability\n",
    "lexicon_idx = np.argmax(posteriors)\n",
    "print(a.Lexicons[lexicon_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1]\n",
      " [1 0 0]]\n",
      "[[1 0 1]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# print top 4 lexicons in the posterior distribution\n",
    "for i in np.argsort(posteriors)[::-1][:2]:\n",
    "    print(a.Lexicons[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>costs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        m1    m2    m3  costs\n",
       "w1     0.0  1.00  1.00      0\n",
       "w2     1.0  0.00  0.00     20\n",
       "prior  0.1  0.45  0.45      0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(a.Lexicons[lexicon_idx], columns=['m1', 'm2', 'm3'], index=['w1', 'w2'])\n",
    "# add row with prior\n",
    "df.loc['prior'] = prior\n",
    "# add column with costs (account for one new row)\n",
    "df['costs'] = np.append(C, 0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colex-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
